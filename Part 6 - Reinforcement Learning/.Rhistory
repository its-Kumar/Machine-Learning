# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
setwd("C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning")
# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
View(dataset)
# Importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Implementing Random Selection
N = 10000
d = 10
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
ad = sample(1:10, 1)
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
total_reward = total_reward + reward
}
# Visualising the results
hist(ads_selected,
col = 'blue',
main = 'Histogram of ads selections',
xlab = 'Ads',
ylab = 'Number of times each ad was selected')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/random_selection.R')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/random_selection.R')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/random_selection.R')
# Impleamenting the UCB
numbers_of_selections = integer(d)
# Impleamenting the UCB
d <- 10
numbers_of_selections <- integer(d)
sums_of_reward <- interger(d)
sums_of_reward <- integer(d)
# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Impleamenting the UCB
N <- 10000
d <- 10
ads_selected <- integer()
numbers_of_selections <- integer(d)
sums_of_reward <- integer(d)
total_reward <- 0
for (n in 1:N){
ad <- 0
max_upper_bound <- 0
for (i in 1:d){
if (numbers_of_selections[i] > 0){
average_reward = sums_of_reward[i] / numbers_of_selections[i]
delta_i = sqrt(3/2 * log(n) / numbers_of_selections[i])
upper_bound = average_reward + delta_i
}
else{
max_upper_bound = 1e400
}
if (upper_bound > max_upper_bound ){
max_upper_bound <- upper_bound
ad <- i
}
}
ads_selected = append(ads_selected, ad)
numbers_of_selections[ad] = numbers_of_selections[ad] + 1
reward = dataset[n, ad]
sums_of_reward[ad] = sums_of_reward[ad] + reward
total_reward = total_reward + reward
}
for (n in 1:N){
ad <- 0
max_upper_bound <- 0
for (i in 1:d){
if (numbers_of_selections[i] > 0){
average_reward = sums_of_reward[i] / numbers_of_selections[i]
delta_i = sqrt(3/2 * log(n) / numbers_of_selections[i])
upper_bound <- average_reward + delta_i
}
else{
max_upper_bound = 1e400
}
if (upper_bound > max_upper_bound ){
max_upper_bound <- upper_bound
ad <- i
}
}
ads_selected = append(ads_selected, ad)
numbers_of_selections[ad] = numbers_of_selections[ad] + 1
reward = dataset[n, ad]
sums_of_reward[ad] = sums_of_reward[ad] + reward
total_reward = total_reward + reward
}
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/Upper Confidence Bound.R')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/Upper Confidence Bound.R')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/Upper Confidence Bound.R')
# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Impleamenting the UCB
N <- 10000
d <- 10
ads_selected <- integer()
numbers_of_selections <- integer(d)
sums_of_reward <- integer(d)
total_reward <- 0
upper_bound <- 0
for (n in 1:N){
ad <- 0
max_upper_bound <- 0
for (i in 1:d){
if (numbers_of_selections[i] > 0){
average_reward = sums_of_reward[i] / numbers_of_selections[i]
delta_i = sqrt(3/2 * log(n) / numbers_of_selections[i])
upper_bound <- average_reward + delta_i
}
else{
max_upper_bound = 1e400
}
if (upper_bound > max_upper_bound ){
max_upper_bound <- upper_bound
ad <- i
}
}
ads_selected = append(ads_selected, ad)
numbers_of_selections[ad] = numbers_of_selections[ad] + 1
reward = dataset[n, ad]
sums_of_reward[ad] = sums_of_reward[ad] + reward
total_reward = total_reward + reward
}
# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Impleamenting the UCB
N = 10000
d = 10
ads_selected = integer()
numbers_of_selections = integer(d)
sums_of_reward = integer(d)
total_reward = 0
# upper_bound = 0
for (n in 1:N){
ad = 0
max_upper_bound = 0
for (i in 1:d){
if (numbers_of_selections[i] > 0){
average_reward = sums_of_reward[i] / numbers_of_selections[i]
delta_i = sqrt(3/2 * log(n) / numbers_of_selections[i])
upper_bound = average_reward + delta_i
}
else{
max_upper_bound = 1e400
}
if (upper_bound > max_upper_bound ){
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
numbers_of_selections[ad] = numbers_of_selections[ad] + 1
reward = dataset[n, ad]
sums_of_reward[ad] = sums_of_reward[ad] + reward
total_reward = total_reward + reward
}
# Importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Implementing UCB
N = 10000
d = 10
ads_selected = integer(0)
numbers_of_selections = integer(d)
sums_of_rewards = integer(d)
total_reward = 0
for (n in 1:N) {
ad = 0
max_upper_bound = 0
for (i in 1:d) {
if (numbers_of_selections[i] > 0) {
average_reward = sums_of_rewards[i] / numbers_of_selections[i]
delta_i = sqrt(3/2 * log(n) / numbers_of_selections[i])
upper_bound = average_reward + delta_i
} else {
upper_bound = 1e400
}
if (upper_bound > max_upper_bound) {
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
numbers_of_selections[ad] = numbers_of_selections[ad] + 1
reward = dataset[n, ad]
sums_of_rewards[ad] = sums_of_rewards[ad] + reward
total_reward = total_reward + reward
}
# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Impleamenting the UCB
N = 10000
d = 10
ads_selected = integer(0)
numbers_of_selections = integer(d)
sums_of_reward = integer(d)
total_reward = 0
for (n in 1:N){
ad = 0
max_upper_bound = 0
for (i in 1:d){
if (numbers_of_selections[i] > 0){
average_reward = sums_of_reward[i] / numbers_of_selections[i]
delta_i = sqrt(3/2 * log(n) / numbers_of_selections[i])
upper_bound = average_reward + delta_i
} else{
upper_bound = 1e400
}
if (upper_bound > max_upper_bound ){
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
numbers_of_selections[ad] = numbers_of_selections[ad] + 1
reward = dataset[n, ad]
sums_of_reward[ad] = sums_of_reward[ad] + reward
total_reward = total_reward + reward
}
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/Upper Confidence Bound.R')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/Upper Confidence Bound.R')
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning/Upper Confidence Bound.R')
ads_selected
numbers_of_selections
sums_of_reward
setwd("C:/Users/Prince_K/Downloads/Machine Learning/Part 6 - Reinforcement Learning")
# importing the dataset
dataset = read.csv('Ads_CTR_Optimisation.csv')
# Impleamenting the UCB
N = 10000
d = 10
ads_selected = integer(0)
numbers_of_rewards_1 = integer(d)
numbers_of_rewards_0 = integer(d)
total_reward = 0
for (n in 1:N){
ad = 0
max_random = 0
for (i in 1:d){
random_beta = rbeta(n = 1,
shape1 = numbers_of_rewards_1[i] +1,
shape2 = numbers_of_rewards_0[i] +1
)
if (random_beta > max_random ){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1){
numbers_of_rewards_1[ad] = numbers_of_rewards_1[ad] + 1
}
else
numbers_of_rewards_0[ad] = numbers_of_rewards_0[ad] + 1
total_reward = total_reward + reward
}
for (n in 1:N){
ad = 0
max_random = 0
for (i in 1:d){
random_beta = rbeta(n = 1,
shape1 = numbers_of_rewards_1[i] +1,
shape2 = numbers_of_rewards_0[i] +1
)
if (random_beta > max_random ){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1){
numbers_of_rewards_1[ad] = numbers_of_rewards_1[ad] + 1
}
else
numbers_of_rewards_0[ad] = numbers_of_rewards_0[ad] + 1
total_reward = total_reward + reward
}
# Impleamenting the UCB
N = 10000
d = 10
ads_selected = integer(0)
numbers_of_rewards_1 = integer(d)
numbers_of_rewards_0 = integer(d)
total_reward = 0
for (n in 1:N){
ad = 0
max_random = 0
for (i in 1:d){
random_beta = rbeta(n = 1,
shape1 = numbers_of_rewards_1[i] +1,
shape2 = numbers_of_rewards_0[i] +1
)
if (random_beta > max_random ){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1){
numbers_of_rewards_1[ad] = numbers_of_rewards_1[ad] + 1
}
else
numbers_of_rewards_0[ad] = numbers_of_rewards_0[ad] + 1
total_reward = total_reward + reward
}
# Visualising the results
hist(ads_selected,
col = 'blue',
main = 'Histogram of ads selections',
xlab = 'Ads',
ylab = 'Number of times each ad was selected')
