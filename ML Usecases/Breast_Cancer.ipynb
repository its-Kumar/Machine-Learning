{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Analysis with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: Line magic function `%matplolib` not found.\n"
    }
   ],
   "source": [
    "%matplolib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".. _breast_cancer_dataset:\n\nBreast cancer wisconsin (diagnostic) dataset\n--------------------------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 569\n\n    :Number of Attributes: 30 numeric, predictive attributes and the class\n\n    :Attribute Information:\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 / area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry \n        - fractal dimension (\"coastline approximation\" - 1)\n\n        The mean, standard error, and \"worst\" or largest (mean of the three\n        largest values) of these features were computed for each image,\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n        13 is Radius SE, field 23 is Worst Radius.\n\n        - class:\n                - WDBC-Malignant\n                - WDBC-Benign\n\n    :Summary Statistics:\n\n    ===================================== ====== ======\n                                           Min    Max\n    ===================================== ====== ======\n    radius (mean):                        6.981  28.11\n    texture (mean):                       9.71   39.28\n    perimeter (mean):                     43.79  188.5\n    area (mean):                          143.5  2501.0\n    smoothness (mean):                    0.053  0.163\n    compactness (mean):                   0.019  0.345\n    concavity (mean):                     0.0    0.427\n    concave points (mean):                0.0    0.201\n    symmetry (mean):                      0.106  0.304\n    fractal dimension (mean):             0.05   0.097\n    radius (standard error):              0.112  2.873\n    texture (standard error):             0.36   4.885\n    perimeter (standard error):           0.757  21.98\n    area (standard error):                6.802  542.2\n    smoothness (standard error):          0.002  0.031\n    compactness (standard error):         0.002  0.135\n    concavity (standard error):           0.0    0.396\n    concave points (standard error):      0.0    0.053\n    symmetry (standard error):            0.008  0.079\n    fractal dimension (standard error):   0.001  0.03\n    radius (worst):                       7.93   36.04\n    texture (worst):                      12.02  49.54\n    perimeter (worst):                    50.41  251.2\n    area (worst):                         185.2  4254.0\n    smoothness (worst):                   0.071  0.223\n    compactness (worst):                  0.027  1.058\n    concavity (worst):                    0.0    1.252\n    concave points (worst):               0.0    0.291\n    symmetry (worst):                     0.156  0.664\n    fractal dimension (worst):            0.055  0.208\n    ===================================== ====== ======\n\n    :Missing Attribute Values: None\n\n    :Class Distribution: 212 - Malignant, 357 - Benign\n\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n    :Donor: Nick Street\n\n    :Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\nConstruction Via Linear Programming.\" Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets\",\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n.. topic:: References\n\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n     San Jose, CA, 1993.\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n     July-August 1995.\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n     163-171.\n"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "print(breast_cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0          17.99         10.38          122.80     1001.0          0.11840   \n1          20.57         17.77          132.90     1326.0          0.08474   \n2          19.69         21.25          130.00     1203.0          0.10960   \n3          11.42         20.38           77.58      386.1          0.14250   \n4          20.29         14.34          135.10     1297.0          0.10030   \n..           ...           ...             ...        ...              ...   \n564        21.56         22.39          142.00     1479.0          0.11100   \n565        20.13         28.25          131.20     1261.0          0.09780   \n566        16.60         28.08          108.30      858.1          0.08455   \n567        20.60         29.33          140.10     1265.0          0.11780   \n568         7.76         24.54           47.92      181.0          0.05263   \n\n     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0             0.27760         0.30010              0.14710         0.2419   \n1             0.07864         0.08690              0.07017         0.1812   \n2             0.15990         0.19740              0.12790         0.2069   \n3             0.28390         0.24140              0.10520         0.2597   \n4             0.13280         0.19800              0.10430         0.1809   \n..                ...             ...                  ...            ...   \n564           0.11590         0.24390              0.13890         0.1726   \n565           0.10340         0.14400              0.09791         0.1752   \n566           0.10230         0.09251              0.05302         0.1590   \n567           0.27700         0.35140              0.15200         0.2397   \n568           0.04362         0.00000              0.00000         0.1587   \n\n     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n0                   0.07871  ...          17.33           184.60      2019.0   \n1                   0.05667  ...          23.41           158.80      1956.0   \n2                   0.05999  ...          25.53           152.50      1709.0   \n3                   0.09744  ...          26.50            98.87       567.7   \n4                   0.05883  ...          16.67           152.20      1575.0   \n..                      ...  ...            ...              ...         ...   \n564                 0.05623  ...          26.40           166.10      2027.0   \n565                 0.05533  ...          38.25           155.00      1731.0   \n566                 0.05648  ...          34.12           126.70      1124.0   \n567                 0.07016  ...          39.42           184.60      1821.0   \n568                 0.05884  ...          30.37            59.16       268.6   \n\n     worst smoothness  worst compactness  worst concavity  \\\n0             0.16220            0.66560           0.7119   \n1             0.12380            0.18660           0.2416   \n2             0.14440            0.42450           0.4504   \n3             0.20980            0.86630           0.6869   \n4             0.13740            0.20500           0.4000   \n..                ...                ...              ...   \n564           0.14100            0.21130           0.4107   \n565           0.11660            0.19220           0.3215   \n566           0.11390            0.30940           0.3403   \n567           0.16500            0.86810           0.9387   \n568           0.08996            0.06444           0.0000   \n\n     worst concave points  worst symmetry  worst fractal dimension  target  \n0                  0.2654          0.4601                  0.11890       0  \n1                  0.1860          0.2750                  0.08902       0  \n2                  0.2430          0.3613                  0.08758       0  \n3                  0.2575          0.6638                  0.17300       0  \n4                  0.1625          0.2364                  0.07678       0  \n..                    ...             ...                      ...     ...  \n564                0.2216          0.2060                  0.07115       0  \n565                0.1628          0.2572                  0.06637       0  \n566                0.1418          0.2218                  0.07820       0  \n567                0.2650          0.4087                  0.12400       0  \n568                0.0000          0.2871                  0.07039       1  \n\n[569 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>564</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>0.05623</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>565</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>0.05533</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>566</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>0.05648</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>567</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>0.07016</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>568</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>0.05884</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dataset = pd.DataFrame(breast_cancer['data'], columns=breast_cancer['feature_names'])\n",
    "dataset['target'] = breast_cancer['target']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "mean radius                0\nmean texture               0\nmean perimeter             0\nmean area                  0\nmean smoothness            0\nmean compactness           0\nmean concavity             0\nmean concave points        0\nmean symmetry              0\nmean fractal dimension     0\nradius error               0\ntexture error              0\nperimeter error            0\narea error                 0\nsmoothness error           0\ncompactness error          0\nconcavity error            0\nconcave points error       0\nsymmetry error             0\nfractal dimension error    0\nworst radius               0\nworst texture              0\nworst perimeter            0\nworst area                 0\nworst smoothness           0\nworst compactness          0\nworst concavity            0\nworst concave points       0\nworst symmetry             0\nworst fractal dimension    0\ntarget                     0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[breast_cancer.feature_names].values\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Logistic Regression to train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                   warm_start=False)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9626373626373627"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.predict([X_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n       1, 1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9473684210526315"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[31,  5],\n       [ 1, 77]])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9473684210526315\n0.9390243902439024\n0.9871794871794872\n0.9625\n"
    }
   ],
   "source": [
    "print(\n",
    "    accuracy_score(y_test, y_pred),\n",
    "    precision_score(y_test, y_pred),\n",
    "    recall_score(y_test, y_pred),\n",
    "    f1_score(y_test, y_pred),\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing accuracy with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.95 \nStandard Deviation: 2.69 \n"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=model, X=X_train, y=y_train, cv=10)\n",
    "print(\"Accuracy: {:.2f} \".format(accuracies.mean()))\n",
    "print(\"Standard Deviation: {:.2f} \".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[31,  5],\n       [ 2, 76]])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9385964912280702\n0.9382716049382716\n0.9743589743589743\n0.9559748427672956\n"
    }
   ],
   "source": [
    "print(\n",
    "    accuracy_score(y_test, y_pred),\n",
    "    precision_score(y_test, y_pred),\n",
    "    recall_score(y_test, y_pred),\n",
    "    f1_score(y_test, y_pred),\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.96 \nStandard Deviation: 2.06 \n"
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=model, X=X_train, y=y_train, cv=10)\n",
    "print(\"Accuracy: {:.2f} \".format(accuracies.mean()))\n",
    "print(\"Standard Deviation: {:.2f} \".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Catboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6s\n613:\tlearn: 0.0202248\ttotal: 16.9s\tremaining: 10.6s\n614:\tlearn: 0.0201539\ttotal: 16.9s\tremaining: 10.6s\n615:\tlearn: 0.0201193\ttotal: 16.9s\tremaining: 10.5s\n616:\tlearn: 0.0200723\ttotal: 16.9s\tremaining: 10.5s\n617:\tlearn: 0.0200233\ttotal: 17s\tremaining: 10.5s\n618:\tlearn: 0.0199741\ttotal: 17s\tremaining: 10.5s\n619:\tlearn: 0.0199449\ttotal: 17s\tremaining: 10.4s\n620:\tlearn: 0.0199037\ttotal: 17.1s\tremaining: 10.4s\n621:\tlearn: 0.0198570\ttotal: 17.1s\tremaining: 10.4s\n622:\tlearn: 0.0197960\ttotal: 17.1s\tremaining: 10.4s\n623:\tlearn: 0.0197526\ttotal: 17.1s\tremaining: 10.3s\n624:\tlearn: 0.0196898\ttotal: 17.2s\tremaining: 10.3s\n625:\tlearn: 0.0196539\ttotal: 17.2s\tremaining: 10.3s\n626:\tlearn: 0.0196230\ttotal: 17.2s\tremaining: 10.3s\n627:\tlearn: 0.0195984\ttotal: 17.3s\tremaining: 10.2s\n628:\tlearn: 0.0195704\ttotal: 17.3s\tremaining: 10.2s\n629:\tlearn: 0.0195530\ttotal: 17.3s\tremaining: 10.2s\n630:\tlearn: 0.0195095\ttotal: 17.4s\tremaining: 10.2s\n631:\tlearn: 0.0194692\ttotal: 17.4s\tremaining: 10.1s\n632:\tlearn: 0.0194209\ttotal: 17.4s\tremaining: 10.1s\n633:\tlearn: 0.0193880\ttotal: 17.5s\tremaining: 10.1s\n634:\tlearn: 0.0193461\ttotal: 17.5s\tremaining: 10.1s\n635:\tlearn: 0.0193169\ttotal: 17.5s\tremaining: 10s\n636:\tlearn: 0.0192708\ttotal: 17.6s\tremaining: 10s\n637:\tlearn: 0.0192124\ttotal: 17.6s\tremaining: 9.98s\n638:\tlearn: 0.0191681\ttotal: 17.6s\tremaining: 9.96s\n639:\tlearn: 0.0191392\ttotal: 17.7s\tremaining: 9.93s\n640:\tlearn: 0.0190899\ttotal: 17.7s\tremaining: 9.9s\n641:\tlearn: 0.0190506\ttotal: 17.7s\tremaining: 9.86s\n642:\tlearn: 0.0190273\ttotal: 17.7s\tremaining: 9.83s\n643:\tlearn: 0.0189900\ttotal: 17.7s\tremaining: 9.8s\n644:\tlearn: 0.0189642\ttotal: 17.8s\tremaining: 9.77s\n645:\tlearn: 0.0189550\ttotal: 17.8s\tremaining: 9.75s\n646:\tlearn: 0.0189112\ttotal: 17.8s\tremaining: 9.72s\n647:\tlearn: 0.0188740\ttotal: 17.8s\tremaining: 9.69s\n648:\tlearn: 0.0188707\ttotal: 17.8s\tremaining: 9.65s\n649:\tlearn: 0.0188406\ttotal: 17.9s\tremaining: 9.62s\n650:\tlearn: 0.0188044\ttotal: 17.9s\tremaining: 9.59s\n651:\tlearn: 0.0187436\ttotal: 17.9s\tremaining: 9.56s\n652:\tlearn: 0.0187043\ttotal: 17.9s\tremaining: 9.53s\n653:\tlearn: 0.0186592\ttotal: 17.9s\tremaining: 9.49s\n654:\tlearn: 0.0186100\ttotal: 18s\tremaining: 9.46s\n655:\tlearn: 0.0185637\ttotal: 18s\tremaining: 9.43s\n656:\tlearn: 0.0185325\ttotal: 18s\tremaining: 9.4s\n657:\tlearn: 0.0185041\ttotal: 18s\tremaining: 9.37s\n658:\tlearn: 0.0184724\ttotal: 18s\tremaining: 9.34s\n659:\tlearn: 0.0184147\ttotal: 18.1s\tremaining: 9.31s\n660:\tlearn: 0.0183595\ttotal: 18.1s\tremaining: 9.28s\n661:\tlearn: 0.0182993\ttotal: 18.1s\tremaining: 9.25s\n662:\tlearn: 0.0182463\ttotal: 18.1s\tremaining: 9.22s\n663:\tlearn: 0.0182336\ttotal: 18.2s\tremaining: 9.19s\n664:\tlearn: 0.0181874\ttotal: 18.2s\tremaining: 9.16s\n665:\tlearn: 0.0181608\ttotal: 18.2s\tremaining: 9.13s\n666:\tlearn: 0.0181030\ttotal: 18.2s\tremaining: 9.1s\n667:\tlearn: 0.0180668\ttotal: 18.3s\tremaining: 9.07s\n668:\tlearn: 0.0180134\ttotal: 18.3s\tremaining: 9.05s\n669:\tlearn: 0.0179684\ttotal: 18.3s\tremaining: 9.02s\n670:\tlearn: 0.0179394\ttotal: 18.3s\tremaining: 9s\n671:\tlearn: 0.0179186\ttotal: 18.4s\tremaining: 8.97s\n672:\tlearn: 0.0178623\ttotal: 18.4s\tremaining: 8.94s\n673:\tlearn: 0.0178337\ttotal: 18.4s\tremaining: 8.91s\n674:\tlearn: 0.0178087\ttotal: 18.5s\tremaining: 8.88s\n675:\tlearn: 0.0177848\ttotal: 18.5s\tremaining: 8.85s\n676:\tlearn: 0.0177651\ttotal: 18.5s\tremaining: 8.82s\n677:\tlearn: 0.0177227\ttotal: 18.5s\tremaining: 8.79s\n678:\tlearn: 0.0176826\ttotal: 18.5s\tremaining: 8.76s\n679:\tlearn: 0.0176632\ttotal: 18.5s\tremaining: 8.73s\n680:\tlearn: 0.0176332\ttotal: 18.6s\tremaining: 8.69s\n681:\tlearn: 0.0175940\ttotal: 18.6s\tremaining: 8.66s\n682:\tlearn: 0.0175895\ttotal: 18.6s\tremaining: 8.63s\n683:\tlearn: 0.0175495\ttotal: 18.6s\tremaining: 8.6s\n684:\tlearn: 0.0175139\ttotal: 18.6s\tremaining: 8.57s\n685:\tlearn: 0.0175018\ttotal: 18.7s\tremaining: 8.54s\n686:\tlearn: 0.0174606\ttotal: 18.7s\tremaining: 8.51s\n687:\tlearn: 0.0174166\ttotal: 18.7s\tremaining: 8.47s\n688:\tlearn: 0.0173602\ttotal: 18.7s\tremaining: 8.44s\n689:\tlearn: 0.0172968\ttotal: 18.7s\tremaining: 8.41s\n690:\tlearn: 0.0172845\ttotal: 18.7s\tremaining: 8.38s\n691:\tlearn: 0.0172627\ttotal: 18.8s\tremaining: 8.35s\n692:\tlearn: 0.0172396\ttotal: 18.8s\tremaining: 8.32s\n693:\tlearn: 0.0172323\ttotal: 18.8s\tremaining: 8.29s\n694:\tlearn: 0.0171963\ttotal: 18.8s\tremaining: 8.26s\n695:\tlearn: 0.0171515\ttotal: 18.8s\tremaining: 8.23s\n696:\tlearn: 0.0170985\ttotal: 18.9s\tremaining: 8.2s\n697:\tlearn: 0.0170448\ttotal: 18.9s\tremaining: 8.16s\n698:\tlearn: 0.0170346\ttotal: 18.9s\tremaining: 8.13s\n699:\tlearn: 0.0170066\ttotal: 18.9s\tremaining: 8.1s\n700:\tlearn: 0.0169746\ttotal: 18.9s\tremaining: 8.07s\n701:\tlearn: 0.0169537\ttotal: 18.9s\tremaining: 8.03s\n702:\tlearn: 0.0169056\ttotal: 18.9s\tremaining: 8s\n703:\tlearn: 0.0168704\ttotal: 19s\tremaining: 7.97s\n704:\tlearn: 0.0168396\ttotal: 19s\tremaining: 7.95s\n705:\tlearn: 0.0167913\ttotal: 19s\tremaining: 7.91s\n706:\tlearn: 0.0167877\ttotal: 19s\tremaining: 7.88s\n707:\tlearn: 0.0167631\ttotal: 19.1s\tremaining: 7.86s\n708:\tlearn: 0.0167474\ttotal: 19.1s\tremaining: 7.83s\n709:\tlearn: 0.0167120\ttotal: 19.1s\tremaining: 7.8s\n710:\tlearn: 0.0167052\ttotal: 19.1s\tremaining: 7.78s\n711:\tlearn: 0.0166692\ttotal: 19.2s\tremaining: 7.75s\n712:\tlearn: 0.0166290\ttotal: 19.2s\tremaining: 7.73s\n713:\tlearn: 0.0165935\ttotal: 19.2s\tremaining: 7.7s\n714:\tlearn: 0.0165712\ttotal: 19.3s\tremaining: 7.67s\n715:\tlearn: 0.0165463\ttotal: 19.3s\tremaining: 7.64s\n716:\tlearn: 0.0165430\ttotal: 19.3s\tremaining: 7.61s\n717:\tlearn: 0.0165079\ttotal: 19.3s\tremaining: 7.58s\n718:\tlearn: 0.0164790\ttotal: 19.3s\tremaining: 7.55s\n719:\tlearn: 0.0164450\ttotal: 19.3s\tremaining: 7.52s\n720:\tlearn: 0.0164076\ttotal: 19.4s\tremaining: 7.49s\n721:\tlearn: 0.0163481\ttotal: 19.4s\tremaining: 7.46s\n722:\tlearn: 0.0163179\ttotal: 19.4s\tremaining: 7.43s\n723:\tlearn: 0.0162791\ttotal: 19.4s\tremaining: 7.4s\n724:\tlearn: 0.0162627\ttotal: 19.4s\tremaining: 7.37s\n725:\tlearn: 0.0162303\ttotal: 19.4s\tremaining: 7.33s\n726:\tlearn: 0.0162000\ttotal: 19.4s\tremaining: 7.3s\n727:\tlearn: 0.0161790\ttotal: 19.5s\tremaining: 7.27s\n728:\tlearn: 0.0161532\ttotal: 19.5s\tremaining: 7.24s\n729:\tlearn: 0.0161343\ttotal: 19.5s\tremaining: 7.21s\n730:\tlearn: 0.0160928\ttotal: 19.5s\tremaining: 7.18s\n731:\tlearn: 0.0160874\ttotal: 19.5s\tremaining: 7.15s\n732:\tlearn: 0.0160478\ttotal: 19.6s\tremaining: 7.12s\n733:\tlearn: 0.0160258\ttotal: 19.6s\tremaining: 7.09s\n734:\tlearn: 0.0160114\ttotal: 19.6s\tremaining: 7.06s\n735:\tlearn: 0.0159844\ttotal: 19.6s\tremaining: 7.03s\n736:\tlearn: 0.0159532\ttotal: 19.6s\tremaining: 7s\n737:\tlearn: 0.0159199\ttotal: 19.6s\tremaining: 6.97s\n738:\tlearn: 0.0158809\ttotal: 19.7s\tremaining: 6.94s\n739:\tlearn: 0.0158498\ttotal: 19.7s\tremaining: 6.91s\n740:\tlearn: 0.0158082\ttotal: 19.7s\tremaining: 6.88s\n741:\tlearn: 0.0157781\ttotal: 19.7s\tremaining: 6.85s\n742:\tlearn: 0.0157435\ttotal: 19.7s\tremaining: 6.82s\n743:\tlearn: 0.0157094\ttotal: 19.7s\tremaining: 6.79s\n744:\tlearn: 0.0156849\ttotal: 19.8s\tremaining: 6.76s\n745:\tlearn: 0.0156466\ttotal: 19.8s\tremaining: 6.73s\n746:\tlearn: 0.0156185\ttotal: 19.8s\tremaining: 6.7s\n747:\tlearn: 0.0155823\ttotal: 19.8s\tremaining: 6.67s\n748:\tlearn: 0.0155458\ttotal: 19.8s\tremaining: 6.64s\n749:\tlearn: 0.0155214\ttotal: 19.8s\tremaining: 6.61s\n750:\tlearn: 0.0154842\ttotal: 19.9s\tremaining: 6.58s\n751:\tlearn: 0.0154576\ttotal: 19.9s\tremaining: 6.56s\n752:\tlearn: 0.0154334\ttotal: 19.9s\tremaining: 6.53s\n753:\tlearn: 0.0153967\ttotal: 19.9s\tremaining: 6.5s\n754:\tlearn: 0.0153600\ttotal: 20s\tremaining: 6.48s\n755:\tlearn: 0.0153549\ttotal: 20s\tremaining: 6.45s\n756:\tlearn: 0.0153267\ttotal: 20s\tremaining: 6.43s\n757:\tlearn: 0.0153003\ttotal: 20s\tremaining: 6.4s\n758:\tlearn: 0.0152808\ttotal: 20.1s\tremaining: 6.38s\n759:\tlearn: 0.0152741\ttotal: 20.1s\tremaining: 6.35s\n760:\tlearn: 0.0152311\ttotal: 20.1s\tremaining: 6.32s\n761:\tlearn: 0.0152126\ttotal: 20.2s\tremaining: 6.3s\n762:\tlearn: 0.0151711\ttotal: 20.2s\tremaining: 6.27s\n763:\tlearn: 0.0151368\ttotal: 20.2s\tremaining: 6.24s\n764:\tlearn: 0.0151139\ttotal: 20.3s\tremaining: 6.22s\n765:\tlearn: 0.0150742\ttotal: 20.3s\tremaining: 6.2s\n766:\tlearn: 0.0150329\ttotal: 20.3s\tremaining: 6.17s\n767:\tlearn: 0.0150023\ttotal: 20.3s\tremaining: 6.14s\n768:\tlearn: 0.0149698\ttotal: 20.4s\tremaining: 6.12s\n769:\tlearn: 0.0149367\ttotal: 20.4s\tremaining: 6.09s\n770:\tlearn: 0.0149017\ttotal: 20.4s\tremaining: 6.07s\n771:\tlearn: 0.0148787\ttotal: 20.5s\tremaining: 6.04s\n772:\tlearn: 0.0148384\ttotal: 20.5s\tremaining: 6.02s\n773:\tlearn: 0.0148134\ttotal: 20.5s\tremaining: 6s\n774:\tlearn: 0.0147901\ttotal: 20.6s\tremaining: 5.97s\n775:\tlearn: 0.0147479\ttotal: 20.6s\tremaining: 5.94s\n776:\tlearn: 0.0147335\ttotal: 20.6s\tremaining: 5.92s\n777:\tlearn: 0.0147036\ttotal: 20.6s\tremaining: 5.89s\n778:\tlearn: 0.0146724\ttotal: 20.7s\tremaining: 5.86s\n779:\tlearn: 0.0146470\ttotal: 20.7s\tremaining: 5.84s\n780:\tlearn: 0.0146067\ttotal: 20.7s\tremaining: 5.81s\n781:\tlearn: 0.0145737\ttotal: 20.7s\tremaining: 5.78s\n782:\tlearn: 0.0145712\ttotal: 20.8s\tremaining: 5.76s\n783:\tlearn: 0.0145482\ttotal: 20.8s\tremaining: 5.74s\n784:\tlearn: 0.0145118\ttotal: 20.9s\tremaining: 5.71s\n785:\tlearn: 0.0144868\ttotal: 20.9s\tremaining: 5.68s\n786:\tlearn: 0.0144634\ttotal: 20.9s\tremaining: 5.66s\n787:\tlearn: 0.0144437\ttotal: 20.9s\tremaining: 5.63s\n788:\tlearn: 0.0144280\ttotal: 20.9s\tremaining: 5.6s\n789:\tlearn: 0.0144032\ttotal: 21s\tremaining: 5.58s\n790:\tlearn: 0.0143802\ttotal: 21s\tremaining: 5.56s\n791:\tlearn: 0.0143682\ttotal: 21.1s\tremaining: 5.53s\n792:\tlearn: 0.0143539\ttotal: 21.1s\tremaining: 5.5s\n793:\tlearn: 0.0143283\ttotal: 21.1s\tremaining: 5.47s\n794:\tlearn: 0.0142975\ttotal: 21.1s\tremaining: 5.45s\n795:\tlearn: 0.0142837\ttotal: 21.2s\tremaining: 5.43s\n796:\tlearn: 0.0142675\ttotal: 21.2s\tremaining: 5.4s\n797:\tlearn: 0.0142190\ttotal: 21.2s\tremaining: 5.37s\n798:\tlearn: 0.0141833\ttotal: 21.2s\tremaining: 5.34s\n799:\tlearn: 0.0141738\ttotal: 21.3s\tremaining: 5.32s\n800:\tlearn: 0.0141260\ttotal: 21.3s\tremaining: 5.29s\n801:\tlearn: 0.0140960\ttotal: 21.3s\tremaining: 5.26s\n802:\tlearn: 0.0140903\ttotal: 21.3s\tremaining: 5.23s\n803:\tlearn: 0.0140709\ttotal: 21.4s\tremaining: 5.21s\n804:\tlearn: 0.0140643\ttotal: 21.4s\tremaining: 5.18s\n805:\tlearn: 0.0140514\ttotal: 21.4s\tremaining: 5.15s\n806:\tlearn: 0.0140293\ttotal: 21.4s\tremaining: 5.13s\n807:\tlearn: 0.0140072\ttotal: 21.5s\tremaining: 5.1s\n808:\tlearn: 0.0140030\ttotal: 21.5s\tremaining: 5.07s\n809:\tlearn: 0.0139797\ttotal: 21.5s\tremaining: 5.04s\n810:\tlearn: 0.0139707\ttotal: 21.5s\tremaining: 5.02s\n811:\tlearn: 0.0139577\ttotal: 21.6s\tremaining: 5s\n812:\tlearn: 0.0139215\ttotal: 21.6s\tremaining: 4.97s\n813:\tlearn: 0.0138979\ttotal: 21.6s\tremaining: 4.94s\n814:\tlearn: 0.0138713\ttotal: 21.7s\tremaining: 4.92s\n815:\tlearn: 0.0138500\ttotal: 21.7s\tremaining: 4.89s\n816:\tlearn: 0.0138321\ttotal: 21.7s\tremaining: 4.86s\n817:\tlearn: 0.0138306\ttotal: 21.7s\tremaining: 4.83s\n818:\tlearn: 0.0138087\ttotal: 21.7s\tremaining: 4.8s\n819:\tlearn: 0.0137753\ttotal: 21.7s\tremaining: 4.77s\n820:\tlearn: 0.0137237\ttotal: 21.8s\tremaining: 4.74s\n821:\tlearn: 0.0137195\ttotal: 21.8s\tremaining: 4.71s\n822:\tlearn: 0.0136992\ttotal: 21.8s\tremaining: 4.69s\n823:\tlearn: 0.0136968\ttotal: 21.8s\tremaining: 4.66s\n824:\tlearn: 0.0136727\ttotal: 21.9s\tremaining: 4.64s\n825:\tlearn: 0.0136564\ttotal: 21.9s\tremaining: 4.61s\n826:\tlearn: 0.0136386\ttotal: 21.9s\tremaining: 4.58s\n827:\tlearn: 0.0136034\ttotal: 22s\tremaining: 4.56s\n828:\tlearn: 0.0136012\ttotal: 22s\tremaining: 4.55s\n829:\tlearn: 0.0135743\ttotal: 22.1s\tremaining: 4.52s\n830:\tlearn: 0.0135522\ttotal: 22.1s\tremaining: 4.5s\n831:\tlearn: 0.0135418\ttotal: 22.1s\tremaining: 4.47s\n832:\tlearn: 0.0135163\ttotal: 22.2s\tremaining: 4.45s\n833:\tlearn: 0.0134998\ttotal: 22.2s\tremaining: 4.42s\n834:\tlearn: 0.0134715\ttotal: 22.2s\tremaining: 4.39s\n835:\tlearn: 0.0134477\ttotal: 22.3s\tremaining: 4.37s\n836:\tlearn: 0.0134349\ttotal: 22.3s\tremaining: 4.34s\n837:\tlearn: 0.0134067\ttotal: 22.3s\tremaining: 4.32s\n838:\tlearn: 0.0133810\ttotal: 22.4s\tremaining: 4.29s\n839:\tlearn: 0.0133568\ttotal: 22.4s\tremaining: 4.27s\n840:\tlearn: 0.0133540\ttotal: 22.4s\tremaining: 4.24s\n841:\tlearn: 0.0133259\ttotal: 22.5s\tremaining: 4.22s\n842:\tlearn: 0.0132982\ttotal: 22.5s\tremaining: 4.19s\n843:\tlearn: 0.0132638\ttotal: 22.5s\tremaining: 4.16s\n844:\tlearn: 0.0132369\ttotal: 22.6s\tremaining: 4.14s\n845:\tlearn: 0.0132337\ttotal: 22.6s\tremaining: 4.11s\n846:\tlearn: 0.0131917\ttotal: 22.6s\tremaining: 4.09s\n847:\tlearn: 0.0131648\ttotal: 22.7s\tremaining: 4.07s\n848:\tlearn: 0.0131605\ttotal: 22.7s\tremaining: 4.04s\n849:\tlearn: 0.0131240\ttotal: 22.7s\tremaining: 4.01s\n850:\tlearn: 0.0131082\ttotal: 22.8s\tremaining: 3.99s\n851:\tlearn: 0.0130855\ttotal: 22.8s\tremaining: 3.96s\n852:\tlearn: 0.0130828\ttotal: 22.8s\tremaining: 3.93s\n853:\tlearn: 0.0130797\ttotal: 22.8s\tremaining: 3.91s\n854:\tlearn: 0.0130574\ttotal: 22.9s\tremaining: 3.88s\n855:\tlearn: 0.0130529\ttotal: 22.9s\tremaining: 3.86s\n856:\tlearn: 0.0130258\ttotal: 22.9s\tremaining: 3.83s\n857:\tlearn: 0.0130059\ttotal: 23s\tremaining: 3.8s\n858:\tlearn: 0.0129789\ttotal: 23s\tremaining: 3.77s\n859:\tlearn: 0.0129429\ttotal: 23s\tremaining: 3.75s\n860:\tlearn: 0.0129301\ttotal: 23s\tremaining: 3.72s\n861:\tlearn: 0.0129141\ttotal: 23s\tremaining: 3.69s\n862:\tlearn: 0.0128942\ttotal: 23.1s\tremaining: 3.66s\n863:\tlearn: 0.0128692\ttotal: 23.1s\tremaining: 3.64s\n864:\tlearn: 0.0128445\ttotal: 23.1s\tremaining: 3.61s\n865:\tlearn: 0.0128420\ttotal: 23.2s\tremaining: 3.59s\n866:\tlearn: 0.0128035\ttotal: 23.2s\tremaining: 3.56s\n867:\tlearn: 0.0127904\ttotal: 23.2s\tremaining: 3.53s\n868:\tlearn: 0.0127570\ttotal: 23.3s\tremaining: 3.5s\n869:\tlearn: 0.0127214\ttotal: 23.3s\tremaining: 3.48s\n870:\tlearn: 0.0127191\ttotal: 23.3s\tremaining: 3.45s\n871:\tlearn: 0.0126961\ttotal: 23.3s\tremaining: 3.42s\n872:\tlearn: 0.0126832\ttotal: 23.4s\tremaining: 3.4s\n873:\tlearn: 0.0126593\ttotal: 23.4s\tremaining: 3.37s\n874:\tlearn: 0.0126472\ttotal: 23.4s\tremaining: 3.35s\n875:\tlearn: 0.0126435\ttotal: 23.5s\tremaining: 3.32s\n876:\tlearn: 0.0126086\ttotal: 23.5s\tremaining: 3.29s\n877:\tlearn: 0.0125824\ttotal: 23.5s\tremaining: 3.27s\n878:\tlearn: 0.0125664\ttotal: 23.6s\tremaining: 3.24s\n879:\tlearn: 0.0125497\ttotal: 23.6s\tremaining: 3.21s\n880:\tlearn: 0.0125477\ttotal: 23.6s\tremaining: 3.19s\n881:\tlearn: 0.0125275\ttotal: 23.6s\tremaining: 3.16s\n882:\tlearn: 0.0125171\ttotal: 23.6s\tremaining: 3.13s\n883:\tlearn: 0.0124853\ttotal: 23.7s\tremaining: 3.11s\n884:\tlearn: 0.0124672\ttotal: 23.7s\tremaining: 3.08s\n885:\tlearn: 0.0124478\ttotal: 23.7s\tremaining: 3.05s\n886:\tlearn: 0.0124453\ttotal: 23.8s\tremaining: 3.03s\n887:\tlearn: 0.0124199\ttotal: 23.8s\tremaining: 3s\n888:\tlearn: 0.0124148\ttotal: 23.8s\tremaining: 2.98s\n889:\tlearn: 0.0123839\ttotal: 23.9s\tremaining: 2.95s\n890:\tlearn: 0.0123827\ttotal: 23.9s\tremaining: 2.92s\n891:\tlearn: 0.0123801\ttotal: 23.9s\tremaining: 2.9s\n892:\tlearn: 0.0123517\ttotal: 23.9s\tremaining: 2.87s\n893:\tlearn: 0.0123467\ttotal: 24s\tremaining: 2.84s\n894:\tlearn: 0.0123303\ttotal: 24s\tremaining: 2.82s\n895:\tlearn: 0.0123260\ttotal: 24s\tremaining: 2.79s\n896:\tlearn: 0.0122921\ttotal: 24.1s\tremaining: 2.76s\n897:\tlearn: 0.0122563\ttotal: 24.1s\tremaining: 2.74s\n898:\tlearn: 0.0122539\ttotal: 24.1s\tremaining: 2.71s\n899:\tlearn: 0.0122519\ttotal: 24.1s\tremaining: 2.68s\n900:\tlearn: 0.0122406\ttotal: 24.2s\tremaining: 2.65s\n901:\tlearn: 0.0122330\ttotal: 24.2s\tremaining: 2.63s\n902:\tlearn: 0.0121942\ttotal: 24.2s\tremaining: 2.6s\n903:\tlearn: 0.0121850\ttotal: 24.2s\tremaining: 2.57s\n904:\tlearn: 0.0121831\ttotal: 24.3s\tremaining: 2.55s\n905:\tlearn: 0.0121574\ttotal: 24.3s\tremaining: 2.52s\n906:\tlearn: 0.0121554\ttotal: 24.3s\tremaining: 2.49s\n907:\tlearn: 0.0121408\ttotal: 24.4s\tremaining: 2.47s\n908:\tlearn: 0.0121266\ttotal: 24.4s\tremaining: 2.44s\n909:\tlearn: 0.0121235\ttotal: 24.4s\tremaining: 2.42s\n910:\tlearn: 0.0121218\ttotal: 24.5s\tremaining: 2.39s\n911:\tlearn: 0.0121090\ttotal: 24.5s\tremaining: 2.36s\n912:\tlearn: 0.0120851\ttotal: 24.5s\tremaining: 2.33s\n913:\tlearn: 0.0120669\ttotal: 24.5s\tremaining: 2.31s\n914:\tlearn: 0.0120635\ttotal: 24.6s\tremaining: 2.28s\n915:\tlearn: 0.0120451\ttotal: 24.6s\tremaining: 2.25s\n916:\tlearn: 0.0120245\ttotal: 24.6s\tremaining: 2.23s\n917:\tlearn: 0.0120008\ttotal: 24.7s\tremaining: 2.2s\n918:\tlearn: 0.0119739\ttotal: 24.7s\tremaining: 2.17s\n919:\tlearn: 0.0119521\ttotal: 24.7s\tremaining: 2.15s\n920:\tlearn: 0.0119301\ttotal: 24.7s\tremaining: 2.12s\n921:\tlearn: 0.0118971\ttotal: 24.7s\tremaining: 2.09s\n922:\tlearn: 0.0118949\ttotal: 24.8s\tremaining: 2.06s\n923:\tlearn: 0.0118714\ttotal: 24.8s\tremaining: 2.04s\n924:\tlearn: 0.0118693\ttotal: 24.8s\tremaining: 2.01s\n925:\tlearn: 0.0118496\ttotal: 24.9s\tremaining: 1.99s\n926:\tlearn: 0.0118190\ttotal: 24.9s\tremaining: 1.96s\n927:\tlearn: 0.0118050\ttotal: 24.9s\tremaining: 1.93s\n928:\tlearn: 0.0117744\ttotal: 25s\tremaining: 1.91s\n929:\tlearn: 0.0117482\ttotal: 25s\tremaining: 1.88s\n930:\tlearn: 0.0117221\ttotal: 25s\tremaining: 1.85s\n931:\tlearn: 0.0117183\ttotal: 25s\tremaining: 1.83s\n932:\tlearn: 0.0117159\ttotal: 25.1s\tremaining: 1.8s\n933:\tlearn: 0.0117044\ttotal: 25.1s\tremaining: 1.77s\n934:\tlearn: 0.0116708\ttotal: 25.1s\tremaining: 1.75s\n935:\tlearn: 0.0116431\ttotal: 25.1s\tremaining: 1.72s\n936:\tlearn: 0.0116095\ttotal: 25.2s\tremaining: 1.69s\n937:\tlearn: 0.0115938\ttotal: 25.2s\tremaining: 1.67s\n938:\tlearn: 0.0115690\ttotal: 25.2s\tremaining: 1.64s\n939:\tlearn: 0.0115602\ttotal: 25.2s\tremaining: 1.61s\n940:\tlearn: 0.0115523\ttotal: 25.2s\tremaining: 1.58s\n941:\tlearn: 0.0115243\ttotal: 25.3s\tremaining: 1.55s\n942:\tlearn: 0.0114857\ttotal: 25.3s\tremaining: 1.53s\n943:\tlearn: 0.0114557\ttotal: 25.3s\tremaining: 1.5s\n944:\tlearn: 0.0114508\ttotal: 25.4s\tremaining: 1.48s\n945:\tlearn: 0.0114486\ttotal: 25.4s\tremaining: 1.45s\n946:\tlearn: 0.0114472\ttotal: 25.4s\tremaining: 1.42s\n947:\tlearn: 0.0114379\ttotal: 25.5s\tremaining: 1.4s\n948:\tlearn: 0.0114222\ttotal: 25.5s\tremaining: 1.37s\n949:\tlearn: 0.0114146\ttotal: 25.5s\tremaining: 1.34s\n950:\tlearn: 0.0114040\ttotal: 25.5s\tremaining: 1.32s\n951:\tlearn: 0.0114025\ttotal: 25.6s\tremaining: 1.29s\n952:\tlearn: 0.0113901\ttotal: 25.6s\tremaining: 1.26s\n953:\tlearn: 0.0113886\ttotal: 25.6s\tremaining: 1.23s\n954:\tlearn: 0.0113869\ttotal: 25.6s\tremaining: 1.21s\n955:\tlearn: 0.0113848\ttotal: 25.7s\tremaining: 1.18s\n956:\tlearn: 0.0113603\ttotal: 25.7s\tremaining: 1.16s\n957:\tlearn: 0.0113539\ttotal: 25.7s\tremaining: 1.13s\n958:\tlearn: 0.0113241\ttotal: 25.7s\tremaining: 1.1s\n959:\tlearn: 0.0113227\ttotal: 25.8s\tremaining: 1.07s\n960:\tlearn: 0.0112961\ttotal: 25.8s\tremaining: 1.05s\n961:\tlearn: 0.0112940\ttotal: 25.8s\tremaining: 1.02s\n962:\tlearn: 0.0112753\ttotal: 25.8s\tremaining: 992ms\n963:\tlearn: 0.0112706\ttotal: 25.8s\tremaining: 965ms\n964:\tlearn: 0.0112585\ttotal: 25.9s\tremaining: 939ms\n965:\tlearn: 0.0112561\ttotal: 25.9s\tremaining: 912ms\n966:\tlearn: 0.0112434\ttotal: 25.9s\tremaining: 885ms\n967:\tlearn: 0.0112416\ttotal: 26s\tremaining: 858ms\n968:\tlearn: 0.0112159\ttotal: 26s\tremaining: 831ms\n969:\tlearn: 0.0111980\ttotal: 26s\tremaining: 804ms\n970:\tlearn: 0.0111733\ttotal: 26s\tremaining: 777ms\n971:\tlearn: 0.0111698\ttotal: 26s\tremaining: 750ms\n972:\tlearn: 0.0111536\ttotal: 26.1s\tremaining: 724ms\n973:\tlearn: 0.0111484\ttotal: 26.1s\tremaining: 697ms\n974:\tlearn: 0.0111232\ttotal: 26.2s\tremaining: 671ms\n975:\tlearn: 0.0111127\ttotal: 26.2s\tremaining: 644ms\n976:\tlearn: 0.0110850\ttotal: 26.3s\tremaining: 618ms\n977:\tlearn: 0.0110824\ttotal: 26.3s\tremaining: 592ms\n978:\tlearn: 0.0110642\ttotal: 26.3s\tremaining: 565ms\n979:\tlearn: 0.0110565\ttotal: 26.4s\tremaining: 538ms\n980:\tlearn: 0.0110491\ttotal: 26.4s\tremaining: 511ms\n981:\tlearn: 0.0110455\ttotal: 26.4s\tremaining: 484ms\n982:\tlearn: 0.0110428\ttotal: 26.4s\tremaining: 457ms\n983:\tlearn: 0.0110407\ttotal: 26.5s\tremaining: 430ms\n984:\tlearn: 0.0110394\ttotal: 26.5s\tremaining: 403ms\n985:\tlearn: 0.0110394\ttotal: 26.5s\tremaining: 377ms\n986:\tlearn: 0.0110383\ttotal: 26.6s\tremaining: 350ms\n987:\tlearn: 0.0110370\ttotal: 26.6s\tremaining: 323ms\n988:\tlearn: 0.0110291\ttotal: 26.6s\tremaining: 296ms\n989:\tlearn: 0.0110061\ttotal: 26.6s\tremaining: 269ms\n990:\tlearn: 0.0110000\ttotal: 26.7s\tremaining: 242ms\n991:\tlearn: 0.0109974\ttotal: 26.7s\tremaining: 215ms\n992:\tlearn: 0.0109960\ttotal: 26.7s\tremaining: 188ms\n993:\tlearn: 0.0109887\ttotal: 26.7s\tremaining: 161ms\n994:\tlearn: 0.0109765\ttotal: 26.8s\tremaining: 135ms\n995:\tlearn: 0.0109696\ttotal: 26.8s\tremaining: 108ms\n996:\tlearn: 0.0109464\ttotal: 26.8s\tremaining: 80.7ms\n997:\tlearn: 0.0109450\ttotal: 26.8s\tremaining: 53.8ms\n998:\tlearn: 0.0109304\ttotal: 26.9s\tremaining: 26.9ms\n999:\tlearn: 0.0109282\ttotal: 26.9s\tremaining: 0us\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x7f1967fc1d10>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier()\n",
    "cat_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cat_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[34,  2],\n       [ 1, 77]])"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9736842105263158\n0.9746835443037974\n0.9871794871794872\n0.980891719745223\n"
    }
   ],
   "source": [
    "print(\n",
    "    accuracy_score(y_test, y_pred),\n",
    "    precision_score(y_test, y_pred),\n",
    "    recall_score(y_test, y_pred),\n",
    "    f1_score(y_test, y_pred),\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.97 \nStandard Deviation: 1.82 \n"
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=cat_model, X=X_train, y=y_train, cv=10)\n",
    "print(\"Accuracy: {:.2f} \".format(accuracies.mean()))\n",
    "print(\"Standard Deviation: {:.2f} \".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitlearningcondacf134821621f44b6a2588003cb8c2979",
   "display_name": "Python 3.7.4 64-bit ('Learning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}