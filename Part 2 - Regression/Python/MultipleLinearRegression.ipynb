{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    R&D Spend  Administration  Marketing Spend       State     Profit\n0   165349.20       136897.80        471784.10    New York  192261.83\n1   162597.70       151377.59        443898.53  California  191792.06\n2   153441.51       101145.55        407934.54     Florida  191050.39\n3   144372.41       118671.85        383199.62    New York  182901.99\n4   142107.34        91391.77        366168.42     Florida  166187.94\n5   131876.90        99814.71        362861.36    New York  156991.12\n6   134615.46       147198.87        127716.82  California  156122.51\n7   130298.13       145530.06        323876.68     Florida  155752.60\n8   120542.52       148718.95        311613.29    New York  152211.77\n9   123334.88       108679.17        304981.62  California  149759.96\n10  101913.08       110594.11        229160.95     Florida  146121.95\n11  100671.96        91790.61        249744.55  California  144259.40\n12   93863.75       127320.38        249839.44     Florida  141585.52\n13   91992.39       135495.07        252664.93  California  134307.35\n14  119943.24       156547.42        256512.92     Florida  132602.65\n15  114523.61       122616.84        261776.23    New York  129917.04\n16   78013.11       121597.55        264346.06  California  126992.93\n17   94657.16       145077.58        282574.31    New York  125370.37\n18   91749.16       114175.79        294919.57     Florida  124266.90\n19   86419.70       153514.11             0.00    New York  122776.86\n20   76253.86       113867.30        298664.47  California  118474.03\n21   78389.47       153773.43        299737.29    New York  111313.02\n22   73994.56       122782.75        303319.26     Florida  110352.25\n23   67532.53       105751.03        304768.73     Florida  108733.99\n24   77044.01        99281.34        140574.81    New York  108552.04\n25   64664.71       139553.16        137962.62  California  107404.34\n26   75328.87       144135.98        134050.07     Florida  105733.54\n27   72107.60       127864.55        353183.81    New York  105008.31\n28   66051.52       182645.56        118148.20     Florida  103282.38\n29   65605.48       153032.06        107138.38    New York  101004.64\n30   61994.48       115641.28         91131.24     Florida   99937.59\n31   61136.38       152701.92         88218.23    New York   97483.56\n32   63408.86       129219.61         46085.25  California   97427.84\n33   55493.95       103057.49        214634.81     Florida   96778.92\n34   46426.07       157693.92        210797.67  California   96712.80\n35   46014.02        85047.44        205517.64    New York   96479.51\n36   28663.76       127056.21        201126.82     Florida   90708.19\n37   44069.95        51283.14        197029.42  California   89949.14\n38   20229.59        65947.93        185265.10    New York   81229.06\n39   38558.51        82982.09        174999.30  California   81005.76\n40   28754.33       118546.05        172795.67  California   78239.91\n41   27892.92        84710.77        164470.71     Florida   77798.83\n42   23640.93        96189.63        148001.11  California   71498.49\n43   15505.73       127382.30         35534.17    New York   69758.98\n44   22177.74       154806.14         28334.72  California   65200.33\n45    1000.23       124153.04          1903.93    New York   64926.08\n46    1315.46       115816.21        297114.46     Florida   49490.75\n47       0.00       135426.92             0.00  California   42559.73\n48     542.05        51743.15             0.00    New York   35673.41\n49       0.00       116983.80         45173.06  California   14681.40",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R&amp;D Spend</th>\n      <th>Administration</th>\n      <th>Marketing Spend</th>\n      <th>State</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165349.20</td>\n      <td>136897.80</td>\n      <td>471784.10</td>\n      <td>New York</td>\n      <td>192261.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>162597.70</td>\n      <td>151377.59</td>\n      <td>443898.53</td>\n      <td>California</td>\n      <td>191792.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153441.51</td>\n      <td>101145.55</td>\n      <td>407934.54</td>\n      <td>Florida</td>\n      <td>191050.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>144372.41</td>\n      <td>118671.85</td>\n      <td>383199.62</td>\n      <td>New York</td>\n      <td>182901.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>142107.34</td>\n      <td>91391.77</td>\n      <td>366168.42</td>\n      <td>Florida</td>\n      <td>166187.94</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>131876.90</td>\n      <td>99814.71</td>\n      <td>362861.36</td>\n      <td>New York</td>\n      <td>156991.12</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>134615.46</td>\n      <td>147198.87</td>\n      <td>127716.82</td>\n      <td>California</td>\n      <td>156122.51</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>130298.13</td>\n      <td>145530.06</td>\n      <td>323876.68</td>\n      <td>Florida</td>\n      <td>155752.60</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>120542.52</td>\n      <td>148718.95</td>\n      <td>311613.29</td>\n      <td>New York</td>\n      <td>152211.77</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>123334.88</td>\n      <td>108679.17</td>\n      <td>304981.62</td>\n      <td>California</td>\n      <td>149759.96</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>101913.08</td>\n      <td>110594.11</td>\n      <td>229160.95</td>\n      <td>Florida</td>\n      <td>146121.95</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100671.96</td>\n      <td>91790.61</td>\n      <td>249744.55</td>\n      <td>California</td>\n      <td>144259.40</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>93863.75</td>\n      <td>127320.38</td>\n      <td>249839.44</td>\n      <td>Florida</td>\n      <td>141585.52</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>91992.39</td>\n      <td>135495.07</td>\n      <td>252664.93</td>\n      <td>California</td>\n      <td>134307.35</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>119943.24</td>\n      <td>156547.42</td>\n      <td>256512.92</td>\n      <td>Florida</td>\n      <td>132602.65</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>114523.61</td>\n      <td>122616.84</td>\n      <td>261776.23</td>\n      <td>New York</td>\n      <td>129917.04</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>78013.11</td>\n      <td>121597.55</td>\n      <td>264346.06</td>\n      <td>California</td>\n      <td>126992.93</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>94657.16</td>\n      <td>145077.58</td>\n      <td>282574.31</td>\n      <td>New York</td>\n      <td>125370.37</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>91749.16</td>\n      <td>114175.79</td>\n      <td>294919.57</td>\n      <td>Florida</td>\n      <td>124266.90</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>86419.70</td>\n      <td>153514.11</td>\n      <td>0.00</td>\n      <td>New York</td>\n      <td>122776.86</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>76253.86</td>\n      <td>113867.30</td>\n      <td>298664.47</td>\n      <td>California</td>\n      <td>118474.03</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>78389.47</td>\n      <td>153773.43</td>\n      <td>299737.29</td>\n      <td>New York</td>\n      <td>111313.02</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>73994.56</td>\n      <td>122782.75</td>\n      <td>303319.26</td>\n      <td>Florida</td>\n      <td>110352.25</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>67532.53</td>\n      <td>105751.03</td>\n      <td>304768.73</td>\n      <td>Florida</td>\n      <td>108733.99</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>77044.01</td>\n      <td>99281.34</td>\n      <td>140574.81</td>\n      <td>New York</td>\n      <td>108552.04</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>64664.71</td>\n      <td>139553.16</td>\n      <td>137962.62</td>\n      <td>California</td>\n      <td>107404.34</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>75328.87</td>\n      <td>144135.98</td>\n      <td>134050.07</td>\n      <td>Florida</td>\n      <td>105733.54</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>72107.60</td>\n      <td>127864.55</td>\n      <td>353183.81</td>\n      <td>New York</td>\n      <td>105008.31</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>66051.52</td>\n      <td>182645.56</td>\n      <td>118148.20</td>\n      <td>Florida</td>\n      <td>103282.38</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>65605.48</td>\n      <td>153032.06</td>\n      <td>107138.38</td>\n      <td>New York</td>\n      <td>101004.64</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>61994.48</td>\n      <td>115641.28</td>\n      <td>91131.24</td>\n      <td>Florida</td>\n      <td>99937.59</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>61136.38</td>\n      <td>152701.92</td>\n      <td>88218.23</td>\n      <td>New York</td>\n      <td>97483.56</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>63408.86</td>\n      <td>129219.61</td>\n      <td>46085.25</td>\n      <td>California</td>\n      <td>97427.84</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>55493.95</td>\n      <td>103057.49</td>\n      <td>214634.81</td>\n      <td>Florida</td>\n      <td>96778.92</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>46426.07</td>\n      <td>157693.92</td>\n      <td>210797.67</td>\n      <td>California</td>\n      <td>96712.80</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>46014.02</td>\n      <td>85047.44</td>\n      <td>205517.64</td>\n      <td>New York</td>\n      <td>96479.51</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>28663.76</td>\n      <td>127056.21</td>\n      <td>201126.82</td>\n      <td>Florida</td>\n      <td>90708.19</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>44069.95</td>\n      <td>51283.14</td>\n      <td>197029.42</td>\n      <td>California</td>\n      <td>89949.14</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>20229.59</td>\n      <td>65947.93</td>\n      <td>185265.10</td>\n      <td>New York</td>\n      <td>81229.06</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>38558.51</td>\n      <td>82982.09</td>\n      <td>174999.30</td>\n      <td>California</td>\n      <td>81005.76</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>28754.33</td>\n      <td>118546.05</td>\n      <td>172795.67</td>\n      <td>California</td>\n      <td>78239.91</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>27892.92</td>\n      <td>84710.77</td>\n      <td>164470.71</td>\n      <td>Florida</td>\n      <td>77798.83</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>23640.93</td>\n      <td>96189.63</td>\n      <td>148001.11</td>\n      <td>California</td>\n      <td>71498.49</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>15505.73</td>\n      <td>127382.30</td>\n      <td>35534.17</td>\n      <td>New York</td>\n      <td>69758.98</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>22177.74</td>\n      <td>154806.14</td>\n      <td>28334.72</td>\n      <td>California</td>\n      <td>65200.33</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1000.23</td>\n      <td>124153.04</td>\n      <td>1903.93</td>\n      <td>New York</td>\n      <td>64926.08</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1315.46</td>\n      <td>115816.21</td>\n      <td>297114.46</td>\n      <td>Florida</td>\n      <td>49490.75</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.00</td>\n      <td>135426.92</td>\n      <td>0.00</td>\n      <td>California</td>\n      <td>42559.73</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>542.05</td>\n      <td>51743.15</td>\n      <td>0.00</td>\n      <td>New York</td>\n      <td>35673.41</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.00</td>\n      <td>116983.80</td>\n      <td>45173.06</td>\n      <td>California</td>\n      <td>14681.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "ct =ColumnTransformer([('encoder', OneHotEncoder(), [3])],\n",
    "remainder='passthrough')\n",
    "X= np.array(ct.fit_transform(X), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05 4.7178410e+05]\n [0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05 4.4389853e+05]\n [1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05 4.0793454e+05]\n [0.0000000e+00 1.0000000e+00 1.4437241e+05 1.1867185e+05 3.8319962e+05]\n [1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04 3.6616842e+05]\n [0.0000000e+00 1.0000000e+00 1.3187690e+05 9.9814710e+04 3.6286136e+05]\n [0.0000000e+00 0.0000000e+00 1.3461546e+05 1.4719887e+05 1.2771682e+05]\n [1.0000000e+00 0.0000000e+00 1.3029813e+05 1.4553006e+05 3.2387668e+05]\n [0.0000000e+00 1.0000000e+00 1.2054252e+05 1.4871895e+05 3.1161329e+05]\n [0.0000000e+00 0.0000000e+00 1.2333488e+05 1.0867917e+05 3.0498162e+05]\n [1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05 2.2916095e+05]\n [0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04 2.4974455e+05]\n [1.0000000e+00 0.0000000e+00 9.3863750e+04 1.2732038e+05 2.4983944e+05]\n [0.0000000e+00 0.0000000e+00 9.1992390e+04 1.3549507e+05 2.5266493e+05]\n [1.0000000e+00 0.0000000e+00 1.1994324e+05 1.5654742e+05 2.5651292e+05]\n [0.0000000e+00 1.0000000e+00 1.1452361e+05 1.2261684e+05 2.6177623e+05]\n [0.0000000e+00 0.0000000e+00 7.8013110e+04 1.2159755e+05 2.6434606e+05]\n [0.0000000e+00 1.0000000e+00 9.4657160e+04 1.4507758e+05 2.8257431e+05]\n [1.0000000e+00 0.0000000e+00 9.1749160e+04 1.1417579e+05 2.9491957e+05]\n [0.0000000e+00 1.0000000e+00 8.6419700e+04 1.5351411e+05 0.0000000e+00]\n [0.0000000e+00 0.0000000e+00 7.6253860e+04 1.1386730e+05 2.9866447e+05]\n [0.0000000e+00 1.0000000e+00 7.8389470e+04 1.5377343e+05 2.9973729e+05]\n [1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05 3.0331926e+05]\n [1.0000000e+00 0.0000000e+00 6.7532530e+04 1.0575103e+05 3.0476873e+05]\n [0.0000000e+00 1.0000000e+00 7.7044010e+04 9.9281340e+04 1.4057481e+05]\n [0.0000000e+00 0.0000000e+00 6.4664710e+04 1.3955316e+05 1.3796262e+05]\n [1.0000000e+00 0.0000000e+00 7.5328870e+04 1.4413598e+05 1.3405007e+05]\n [0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05 3.5318381e+05]\n [1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05 1.1814820e+05]\n [0.0000000e+00 1.0000000e+00 6.5605480e+04 1.5303206e+05 1.0713838e+05]\n [1.0000000e+00 0.0000000e+00 6.1994480e+04 1.1564128e+05 9.1131240e+04]\n [0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05 8.8218230e+04]\n [0.0000000e+00 0.0000000e+00 6.3408860e+04 1.2921961e+05 4.6085250e+04]\n [1.0000000e+00 0.0000000e+00 5.5493950e+04 1.0305749e+05 2.1463481e+05]\n [0.0000000e+00 0.0000000e+00 4.6426070e+04 1.5769392e+05 2.1079767e+05]\n [0.0000000e+00 1.0000000e+00 4.6014020e+04 8.5047440e+04 2.0551764e+05]\n [1.0000000e+00 0.0000000e+00 2.8663760e+04 1.2705621e+05 2.0112682e+05]\n [0.0000000e+00 0.0000000e+00 4.4069950e+04 5.1283140e+04 1.9702942e+05]\n [0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04 1.8526510e+05]\n [0.0000000e+00 0.0000000e+00 3.8558510e+04 8.2982090e+04 1.7499930e+05]\n [0.0000000e+00 0.0000000e+00 2.8754330e+04 1.1854605e+05 1.7279567e+05]\n [1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04 1.6447071e+05]\n [0.0000000e+00 0.0000000e+00 2.3640930e+04 9.6189630e+04 1.4800111e+05]\n [0.0000000e+00 1.0000000e+00 1.5505730e+04 1.2738230e+05 3.5534170e+04]\n [0.0000000e+00 0.0000000e+00 2.2177740e+04 1.5480614e+05 2.8334720e+04]\n [0.0000000e+00 1.0000000e+00 1.0002300e+03 1.2415304e+05 1.9039300e+03]\n [1.0000000e+00 0.0000000e+00 1.3154600e+03 1.1581621e+05 2.9711446e+05]\n [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3542692e+05 0.0000000e+00]\n [0.0000000e+00 1.0000000e+00 5.4205000e+02 5.1743150e+04 0.0000000e+00]\n [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1698380e+05 4.5173060e+04]]\n"
    }
   ],
   "source": [
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[103015.20159796 132582.27760816 132447.73845175  71976.09851259\n 178537.48221054 116161.24230163  67851.69209676  98791.73374688\n 113969.43533012 167921.0656955 ]\n"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.001\nModel:                            OLS   Adj. R-squared:                 -0.020\nMethod:                 Least Squares   F-statistic:                   0.04727\nDate:                Mon, 20 Apr 2020   Prob (F-statistic):              0.829\nTime:                        00:03:55   Log-Likelihood:                -600.63\nNo. Observations:                  50   AIC:                             1205.\nDf Residuals:                      48   BIC:                             1209.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       1.111e+05   7085.628     15.682      0.000    9.69e+04    1.25e+05\nx1          2642.1322   1.22e+04      0.217      0.829   -2.18e+04    2.71e+04\n==============================================================================\nOmnibus:                        0.011   Durbin-Watson:                   0.021\nProb(Omnibus):                  0.994   Jarque-Bera (JB):                0.082\nSkew:                           0.022   Prob(JB):                        0.960\nKurtosis:                       2.807   Cond. No.                         2.41\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.001</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.020</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.04727</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 20 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.829</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>00:03:55</td>     <th>  Log-Likelihood:    </th> <td> -600.63</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1205.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1209.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 1.111e+05</td> <td> 7085.628</td> <td>   15.682</td> <td> 0.000</td> <td> 9.69e+04</td> <td> 1.25e+05</td>\n</tr>\n<tr>\n  <th>x1</th>    <td> 2642.1322</td> <td> 1.22e+04</td> <td>    0.217</td> <td> 0.829</td> <td>-2.18e+04</td> <td> 2.71e+04</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.011</td> <th>  Durbin-Watson:     </th> <td>   0.021</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.994</td> <th>  Jarque-Bera (JB):  </th> <td>   0.082</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.022</td> <th>  Prob(JB):          </th> <td>   0.960</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.807</td> <th>  Cond. No.          </th> <td>    2.41</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Backward elimination\n",
    "import statsmodels.regression.linear_model as sm\n",
    "X = np.append(arr =np.ones((50,1)).astype(int), values =X ,axis=1)\n",
    "X_opt = X[:, [0,1,2,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "\n",
    "X_opt = X[:, [0,1,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog= X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog= X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0,3,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog= X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0,3]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog= X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}